{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlzfQumgj7rh",
        "outputId": "32566b76-8230-46cd-b0e1-a5ba39d6bb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "2hcUbmcjj_iF",
        "outputId": "42e015da-7383-4a5f-9179-15932f7c1f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opacus in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.21.6)\n",
            "Requirement already satisfied: functorch in /usr/local/lib/python3.7/dist-packages (from opacus) (1.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (4.1.1)\n",
            "Collecting torch>=1.8\n",
            "  Using cached torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (57.4.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1\n",
            "    Uninstalling torch-1.12.1:\n",
            "      Successfully uninstalled torch-1.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "q-pp5OiNN3jk",
        "outputId": "fa4f2f8b-cfae-4a12-f342-271f164d7630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from medmnist) (4.64.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from medmnist) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.13.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (from medmnist) (0.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from medmnist) (0.18.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from medmnist) (7.1.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->medmnist) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire->medmnist) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->medmnist) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (1.7.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (4.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.7/dist-packages (from torch->medmnist) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.7/dist-packages (from torch->medmnist) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.7/dist-packages (from torch->medmnist) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.7/dist-packages (from torch->medmnist) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->medmnist) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->medmnist) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->medmnist) (2.23.0)\n",
            "Collecting torch\n",
            "  Using cached torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (3.0.4)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0\n",
            "    Uninstalling torch-1.13.0:\n",
            "      Successfully uninstalled torch-1.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "functorch 1.13.0 requires torch<1.13.1,>=1.13.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6fDI-ulbJmU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import optim, analysis, sampling\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from torchvision.models import ResNeXt101_64X4D_Weights\n",
        "import torch.nn.functional as F\n",
        "#import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset \n",
        "from torch.utils.data import DataLoader, random_split  \n",
        "torch.backends.cudnn.benchmark=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zTi6YtPN8Dk"
      },
      "outputs": [],
      "source": [
        "data_flag = 'bloodmnist'\n",
        "download = True\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxerzR86bN6n"
      },
      "outputs": [],
      "source": [
        "##### Hyperparameters for federated learning #########\n",
        "batch_size = 64\n",
        "num_channels = 3\n",
        "data_dir = 'data/'\n",
        "\n",
        "params = {'l2_norm_clip': 1,\n",
        "          'noise_multiplier' :1.1,\n",
        "          'minibatch_size': 256,\n",
        "         'microbatch_size': 1,\n",
        "         'lr':0.15,\n",
        "         'l2_penalty' : 0,\n",
        "         'delta' : 1e-5,\n",
        "         'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "         'local_epochs' : 3,\n",
        "          \"total_clients\": 3,\n",
        "          \"num_sel\":3,\n",
        "          \"num_rounds\": 50}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt-BctUeQis6",
        "outputId": "e667ed71-12b3-4b99-f95e-16d416669b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_datasets():\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean  = (0.49139968, 0.48215827, 0.44653124), std = (0.24703233,\n",
        "                                                                              0.24348505, 0.26158768))])\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #  transforms.Resize((224,224)),\n",
        "    # transforms.ToTensor(), \n",
        "    # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "    # train_dataset = datasets.OxfordIIITPet(root='/data', split = 'trainval', download=True, transform=transform)\n",
        "    # test_dataset = datasets.OxfordIIITPet(root='/data', split = 'test', download=True, transform=transform)\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(data_dir, train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.CIFAR10(data_dir, train=False, transform=transform, download=True)\n",
        "\n",
        "    # train_dataset = datasets.SVHN(data_dir, split = 'train', transform=transform, download=True)\n",
        "    # test_dataset = datasets.SVHN(data_dir, split = 'test', transform=transform, download=True)\n",
        "\n",
        "\n",
        "    #train_dataset = DataClass(split='train', transform=transform, download=download)\n",
        "    #test_dataset  = DataClass(split='test', transform=transform, download=download)\n",
        "\n",
        "    # Split training set into clients to simulate the individual dataset\n",
        "    #partition_size = len(train_dataset) // params['total_clients']\n",
        "    #lengths = [partition_size] * params['total_clients'] ## This line may need more explanation\n",
        "\n",
        "    train_datasets = random_split(train_dataset, [len(train_dataset)-2,2])\n",
        "    train_datasets = random_split(train_datasets[0], [int((len(train_dataset))/ params['total_clients']) for _ in range(params['total_clients'])])\n",
        "    \n",
        "    #train_datasets = random_split(train_dataset, [int(train_dataset.data.shape[0] / params['total_clients']) for _ in range(params['total_clients'])])\n",
        "\n",
        "    \n",
        "    return train_datasets, test_dataset\n",
        "\n",
        "train_datasets, test_dataset = load_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pit6D0VDRBVh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxQKo__PijB_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8xmE__eQ2y0"
      },
      "outputs": [],
      "source": [
        "class MNISTResNet(nn.Module):\n",
        "        def __init__(self, in_channels=1):\n",
        "                super(MNISTResNet, self).__init__()\n",
        "                # loading a pretrained model\n",
        "                #self.model = torchvision.models.resnet152(pretrained = True)\n",
        "                self.model = torchvision.models.resnext101_64x4d(weights = None)\n",
        "                #self.model = torchvision.models.resnext50_32x4d(pretrained = True)\n",
        "                # self.model = torchvision.models.resnet152(pretrained = True)\n",
        "                #self.model = torchvision.models.resnet50(pretrained = True)\n",
        "                #self.model = torchvision.models.resnet18(pretrained = True)\n",
        "                # changing the input color channels to 1 since original resnet has 3 channels for RGB\n",
        "                #self.model.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "                #change the output layer to 10 ckasses as the original resnet has 1000 classes\n",
        "                num_ftrs = self.model.fc.in_features\n",
        "                #self.model.fc = nn.Linear(num_ftrs, 10)\n",
        "                #self.model.fc = nn.Linear(num_ftrs, 37)\n",
        "                self.model.fc = nn.Linear(num_ftrs, 8)\n",
        "                # for name,param in self.model.named_parameters():\n",
        "                #     if(name == 'fc.weight'):\n",
        "                #         param.requires_grad =True\n",
        "                #     elif(name =='fc.bias'):\n",
        "                #         param.requires_grad = True\n",
        "                #     else:\n",
        "                #         param.requires_grad = False\n",
        "        def forward(self, t):\n",
        "                return self.model(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SYJIahw5Tae"
      },
      "outputs": [],
      "source": [
        "def client_update(client_model, train_dataset):\n",
        "  \n",
        "  \n",
        "  classifier = client_model\n",
        "\n",
        "  optimizer = optim.DPSGD(\n",
        "        l2_norm_clip=params['l2_norm_clip'],\n",
        "        noise_multiplier=params['noise_multiplier'],\n",
        "        minibatch_size=params['minibatch_size'],\n",
        "        microbatch_size=params['microbatch_size'],\n",
        "        params = filter(lambda p: p.requires_grad, classifier.parameters()),\n",
        "        lr=params['lr'],\n",
        "        weight_decay=params['l2_penalty'],\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    #print('Achieves ({}, {})-DP'.format(analysis.epsilon(len(train_dataset),params['minibatch_size'],params['noise_multiplier'],params['iterations'],params['delta']),params['delta'],))\n",
        "\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  minibatch_loader, microbatch_loader = sampling.get_data_loaders(\n",
        "        params['minibatch_size'],\n",
        "        params['microbatch_size'],\n",
        "        params['local_epochs']\n",
        "    )\n",
        "\n",
        "    #iteration = 0\n",
        "    #acc = []\n",
        "  for X_minibatch, y_minibatch in minibatch_loader(train_dataset):\n",
        "        optimizer.zero_grad()\n",
        "        y_minibatch = torch.squeeze(y_minibatch)\n",
        "        for X_microbatch, y_microbatch in microbatch_loader(TensorDataset(X_minibatch, y_minibatch)):\n",
        "            \n",
        "            # weights = ResNet50_Weights.DEFAULT\n",
        "            # preprocess = weights.transforms()\n",
        "            # X_microbatch = preprocess(X_microbatch)\n",
        "            X_microbatch = X_microbatch.to(params['device'])\n",
        "            y_microbatch = y_microbatch.to(params['device'])\n",
        "\n",
        "            optimizer.zero_microbatch_grad()\n",
        "            loss = loss_function(classifier(X_microbatch), y_microbatch)\n",
        "            loss.backward()\n",
        "            optimizer.microbatch_step()\n",
        "        optimizer.step()\n",
        "\n",
        "        # if iteration % 10 == 0:\n",
        "        #     acc.append(test())\n",
        "        #     print('Achieves ({}, {})-DP'.format(analysis.epsilon(len(train_dataset),params['minibatch_size'],params['noise_multiplier'],iteration,params['delta']),params['delta'],))\n",
        "        #     print('[Iteration %d/%d] [Loss: %f]' % (iteration, params['iterations'], loss.item()))\n",
        "\n",
        "        #iteration += 1\n",
        "\n",
        "    #return classifier,acc\n",
        "  return classifier,loss.item() #,val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAtTgU6-4X9v"
      },
      "outputs": [],
      "source": [
        "\n",
        "def server_aggregate(global_model, client_models):\n",
        "    \"\"\"\n",
        "    This function has aggregation method 'mean'\n",
        "    \"\"\"\n",
        "\n",
        "    global_dict = global_model.state_dict()\n",
        "    for k in global_dict.keys(): \n",
        "      global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
        "      global_model.load_state_dict(global_dict)\n",
        "    \n",
        "    global_model.load_state_dict(global_dict)\n",
        "    for model in client_models:\n",
        "      model.load_state_dict(global_model.state_dict())\n",
        "    \n",
        "    return client_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNFYeW-aSRN0"
      },
      "outputs": [],
      "source": [
        "def test(model):\n",
        "\n",
        "  classifier = model\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "  classifier.eval()\n",
        "  accuracy = 0.0\n",
        "  total = 0.0\n",
        "  with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            # weights = ResNet50_Weights.DEFAULT\n",
        "            # preprocess = weights.transforms()\n",
        "            # images = preprocess(images)\n",
        "            images = images.to(params['device'])\n",
        "            labels = torch.squeeze(labels)\n",
        "            labels = labels.to(params['device'])\n",
        "            \n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = classifier(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "    # compute the accuracy over all test images|\n",
        "  accuracy = (100 * accuracy / total)\n",
        "  #print('Test Accuracy: {}'.format(accuracy))\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8V8qg7ZK4-p"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "#### Initializing models and optimizer  ####\n",
        "############################################\n",
        "\n",
        "#### global model ##########\n",
        "import opacus\n",
        "from opacus.validators import ModuleValidator\n",
        "global_model =  MNISTResNet()\n",
        "global_model = ModuleValidator.fix(global_model ).to(params['device'])\n",
        "ModuleValidator.validate(global_model , strict=False)\n",
        "\n",
        "############## client models ##############\n",
        "client_models = [ ModuleValidator.fix(MNISTResNet()).to(params['device']) for _ in range(params[\"num_sel\"])]\n",
        "for model in client_models:\n",
        "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
        "\n",
        "############### optimizers ################\n",
        "#opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95cjuxXnFIN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275fe145-e302-43cd-9b04-0af4a55ce2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 7, 7])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 4, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 4, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 4, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([512, 256, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 8, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 256, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 8, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 8, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 8, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([1024, 512, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 512, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 16, 3, 3])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024, 1024, 1, 1])\n",
            "torch.Size([1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([2048, 1024, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 32, 3, 3])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 2048, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 1024, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 2048, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 32, 3, 3])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 2048, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 2048, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 32, 3, 3])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048, 2048, 1, 1])\n",
            "torch.Size([2048])\n",
            "torch.Size([2048])\n",
            "torch.Size([8, 2048])\n",
            "torch.Size([8])\n",
            "81422664\n"
          ]
        }
      ],
      "source": [
        "#client_models = server_aggregate(global_model, client_models)\n",
        "parameter_count = 0\n",
        "for p in global_model.parameters():\n",
        "  if(p.requires_grad):\n",
        "    #print(torch.numel(p))\n",
        "    parameter_count+=torch.numel(p)\n",
        "    print(p.size())\n",
        "\n",
        "print(parameter_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZwXV6Zd6rO3"
      },
      "outputs": [],
      "source": [
        "\n",
        "#net = global_model.to(device)\n",
        "\n",
        "# for epoch in range(200):\n",
        "#     global_model,loss= client_update(global_model, train_datasets[0])\n",
        "#     if(epoch%10==0):\n",
        "#       acc = test(global_model)\n",
        "#       print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {acc}\")\n",
        "   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS5I6gvNSabe"
      },
      "outputs": [],
      "source": [
        "#  client_idx = np.random.permutation(params[\"total_clients\"])[:params[\"num_sel\"]]\n",
        "#  print(client_idx )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP7Gp94LJxTc"
      },
      "outputs": [],
      "source": [
        "# losses_train = []\n",
        "# losses_test = []\n",
        "# acc_train = []\n",
        "# acc_test = []\n",
        "\n",
        "# for r in range(params[\"num_rounds\"]):\n",
        "#     # select random clients\n",
        "#     # \"total_clients\": 4,\n",
        "#     #       \"num_sel\":4,\n",
        "#     client_idx = np.random.permutation(params[\"total_clients\"])[:params[\"num_sel\"]]\n",
        "#     #client_idx =[1,2,3]\n",
        "#     # client update\n",
        "#     loss = 0\n",
        "#     temp = 0\n",
        "#     temp1 = 0\n",
        "#     val_acc = 0\n",
        "#     for i in tqdm(range(params[\"num_sel\"])):\n",
        "#       for j in tqdm(range(params['local_epochs'])):\n",
        "#         client_models[i],loss_temp = client_update(client_models[i], train_datasets[client_idx[i]])\n",
        "#       client_models[i].eval()\n",
        "#       loss+=loss_temp \n",
        "#     losses_train.append(loss)\n",
        "#     losses_train.append(loss)\n",
        "#     # server aggregate\n",
        "#     client_models = server_aggregate(global_model, client_models)\n",
        "\n",
        "#     # _,val_acc = test(global_model,valloaders[0])\n",
        "\n",
        "#     if(r%10==0):\n",
        "#       acc = test(global_model)\n",
        "\n",
        "#       acc_test.append(acc)\n",
        "#       print('%d-th round' % r)\n",
        "#       print('average train loss %0.3g  | test acc: %0.3f' % (loss / params[\"num_sel\"], acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAYgso41PYGB"
      },
      "outputs": [],
      "source": [
        "#test(global_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep3J8IVf3WCQ"
      },
      "outputs": [],
      "source": [
        "#acc_test.append(test(global_model))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSe93wQW62nU"
      },
      "outputs": [],
      "source": [
        "#acc_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8uQ8vgc7RyF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}